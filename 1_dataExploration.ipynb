{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 1\n",
    "train_size = 0.75\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data in a dataframe and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file (or url) and save the dataframe\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "df = pd.read_csv(url, sep = ';') \n",
    "# if the names of the columns are not present, insert them using `names = []`\n",
    "# if the file is an excel use df = pd.read_excel(data_fn)\n",
    "print(f\"Shape of the input data {df.shape}\")\n",
    "\n",
    "target = 'quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the name of the columns\n",
    "print(df.columns)\n",
    "# showing the first rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the unique class labels\n",
    "classes = df[target].unique()\n",
    "classes.sort()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating descriptive statistics of the dataframe\n",
    "# it's also possible to have description of a single feature using \n",
    "# df['feature'].describe()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the rows with null values\n",
    "print(f\"Number of rows with null values: {df.shape[0] - df.dropna().shape[0]}\")\n",
    "df1 = df.dropna().copy()\n",
    "print(f\"After dropping rows with nulls the dataset has {df1.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some descriptions represent the same item but have different leading or trailing spaces,\n",
    "# therefore they must be made uniform with the Pandas' function `str.strip()`\n",
    "df1 = df\n",
    "df1['Description'] = df['Description'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows with missing InvoiceNo before removing\")\n",
    "df1[df1['InvoiceNo'].isna()]\n",
    "\n",
    "df2 = df1.dropna(axis=0, subset=['InvoiceNo'])\n",
    "\n",
    "print(\"Rows with missing InvoiceNo after removing\")\n",
    "df2[df2['InvoiceNo'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the column with a C in InvoiceNo\n",
    "# in order to be able to use string functions, such as `contains`, \n",
    "# the column must be transformed into `str` with `astype`.\n",
    "print(f\"There are {sum(df2['InvoiceNo'].astype('str').str.contains('C'))} rows containing 'C' in 'InvoiceNo'\")\n",
    "\n",
    "df3 = df2[~df2['InvoiceNo'].astype('str').str.contains('C')]\n",
    "\n",
    "print(\"After removal, there are {} rows containing 'C' in 'InvoiceNo'\"\\\n",
    "      .format(sum(df3['InvoiceNo'].astype('str').str.contains('C'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions:\n",
    "# 1. filter the rows ``Country`='France'`\n",
    "# 2. group by `['InvoiceNo', 'Description']` computing a sum on `['Quantity']`\n",
    "# 3. use the `unstack` function to move the items from rows to columns\n",
    "# 4. reset the index\n",
    "# 5. fill the missing with zero (`fillna(0)`)\n",
    "# 6. store the result in the new dataframe `basket` and inspect it\n",
    "basket = (df3[df3['Country'] ==\"France\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    "basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a lot of zeros in the data but we also need to make sure any \n",
    "# positive values are converted to a 1 and anything less than 0 is set to 0.\n",
    "encode_units = lambda x: 0 if x <= 0 else 1\n",
    "basket_sets = basket.applymap(encode_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation\n",
    "# convert an alphanumeric number into numeric 0 and 1\n",
    "df1['SexHRP']=df1['SexHRP'].apply(lambda x: 0 if (x=='Female') else 1)\n",
    "# generate two new columns\n",
    "df1['qmeat_hhsize_ratio'] = df1['qmeat']/df1['hhsize']\n",
    "df1['income_hhsize_ratio'] = df1['income']/df1['hhsize']\n",
    "\n",
    "# use only the most important feature\n",
    "df = df1[['adults_n', 'children_n', 'SexHRP', 'AgeHRP'\n",
    "        , 'qmeat_hhsize_ratio', 'income_hhsize_ratio', 'uvmeat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Converting the attribute 'a3' to numeric\n",
    "enc = OrdinalEncoder()\n",
    "df[['a3']] = enc.fit_transform(df[['a3']])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the histogram of the dataset\n",
    "# it's also possible to have the histogram of a single feature using \n",
    "# plt.hist(df['quality']) and plt.show()\n",
    "pd.DataFrame.hist(df\n",
    "                  , figsize = [10,10]\n",
    "                 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting pairwise relationships in the dataframe\n",
    "sns.pairplot(df, hue=target) #, height=2) # diag_kws={'bw': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing pairwise correlation of columns\n",
    "corr = df[df.columns].corr()\n",
    "sns.heatmap(corr, cmap=\"YlGnBu\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outliers and observing the data distribution\n",
    "\n",
    "# plt.figure(figsize=(15,15))\n",
    "# pos = 1\n",
    "# for i in df.columns:\n",
    "#     plt.subplot(3, 4, pos)\n",
    "#     sns.boxplot(df[i])\n",
    "#     pos += 1\n",
    "\n",
    "numCol = len(df.columns)\n",
    "a1 = int(math.sqrt(numCol))\n",
    "a2 = int(numCol/a1)\n",
    "if (numCol%a1)>0:\n",
    "    a2 += 1\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "pos = 1\n",
    "for i in df.columns:\n",
    "    plt.subplot(a1, a2, pos)\n",
    "    sns.boxplot(df[i])\n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot to check the outliers (using this we have only one plot)\n",
    "sns.boxplot(data = df)\n",
    "sns.boxplot(x='quality', y='fixed acidity', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the two dimensional scatter plots for all \n",
    "# the predicting variables with respect to the target\n",
    "ncols=3\n",
    "nrows = math.ceil((df.shape[1]-1)/ncols)\n",
    "figwidth = ncols * 7\n",
    "figheigth = nrows*5\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(figwidth, figheigth),sharey=True)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle(\"Predicting variables versus target\", fontsize=18, y=0.95)\n",
    "\n",
    "for c, ax in zip(df.drop(target,axis=1).columns,axs.ravel()):\n",
    "    df.sort_values(by=c).plot.scatter(x=c, y=target, \\\n",
    "        title = '\"{}\" versus \"{}\"'.format(target,c), ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing in X the content of the dataframe excluding the target column\n",
    "X = df.drop(target, axis=1)\n",
    "# storing in y the labels\n",
    "y = df[target]\n",
    "print(f\"Shape of X: {X.shape}\\nShape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the dataset in train and test\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state, train_size = train_size)\n",
    "print(\"There are {} samples in the training dataset\".format(Xtrain.shape[0]))\n",
    "print(\"There are {} samples in the testing dataset\".format(Xtest.shape[0]))\n",
    "print(\"Each sample has {} features\".format(Xtrain.shape[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operation for clustering\n",
    "If plotting using the pairplot we see that some data are highhly concentrated on a side of the plot, we could apply some operation (for example the square root).\n",
    "Then we could remap all the variables in the range 0:1 so that clistering is more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sqrt = pd.concat([df.iloc[:,:2],df.iloc[:,2:].applymap(math.sqrt)],axis=1)\n",
    "\n",
    "# remap on the 0:1 range with MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X = pd.DataFrame(mms.fit_transform(X_sqrt), columns = X_sqrt.columns)\n",
    "X.head()\n",
    "\n",
    "# show the transformation\n",
    "X.boxplot(figsize=(15,8));\n",
    "plt.show()\n",
    "sns.pairplot(X);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
