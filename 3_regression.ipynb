{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "random_state = 1\n",
    "train_size = 0.75\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import scipy.stats\n",
    "# Computation of F-statistic and p-value for the regression\n",
    "# http://facweb.cs.depaul.edu/sjost/csc423/documents/f-test-reg.htm\n",
    "def f_test(y_true, y_pred, n_var, n_obs, sn=.95):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    n = n_obs\n",
    "    p = n_var+1 # number of regression parameters (coefficients + intercept)\n",
    "    y_true_m = np.mean(y_true)\n",
    "    SSM = np.sum((y_pred-y_true_m)**2)\n",
    "    SST = np.sum((y_true-y_true_m)**2)\n",
    "    SSE = np.sum((y_true-y_pred)**2)\n",
    "    DFT = n - 1\n",
    "    DFM = p - 1 # degrees of freedom for model - numerator\n",
    "    DFE = n - p # degrees of freedom for error - denominator\n",
    "    DFT = n - 1\n",
    "    MSM = SSM / DFM\n",
    "    MSE = SSE / DFE \n",
    "    MST = SST / DFT\n",
    "    F = MSM / MSE\n",
    "    p = 1-scipy.stats.f.cdf(F, DFM, DFE) #find p-value of F test statistic \n",
    "    return F, p\n",
    "    \n",
    "def print_eval(X, y, model):\n",
    "    pred = model.predict(X)\n",
    "    F, p = f_test(y, pred, X.shape[1], X.shape[0])\n",
    "    print(\" Mean squared error: \\t{:.5}\".format(mean_squared_error(y,pred)))\n",
    "    print(\" r2 score: \\t\\t{:.5}\".format(r2_score(y,pred)))\n",
    "    print(\" f-statistic: \\t\\t{:.5}\".format(F))\n",
    "    print(\" p-value: \\t\\t{:.5}\".format(p))\n",
    "    return mean_squared_error(pred, y), r2_score(pred, y), F, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file (or url) and save the dataframe\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "df = pd.read_csv(url, sep = ';') \n",
    "# if the names of the columns are not present, insert them using `names = []`\n",
    "# if the file is an excel use df = pd.read_excel(data_fn)\n",
    "print(f\"Shape of the input data {df.shape}\")\n",
    "\n",
    "target = 'quality'\n",
    "\n",
    "# storing in X the content of the dataframe excluding the target column\n",
    "X = df.drop(target, axis=1)\n",
    "# storing in y the labels\n",
    "y = df[target]\n",
    "print(f\"Shape of X: {X.shape}\\nShape of y: {y.shape}\")\n",
    "\n",
    "# dividing the dataset in train and test\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=random_state, train_size = train_size)\n",
    "print(\"There are {} samples in the training dataset\".format(Xtrain.shape[0]))\n",
    "print(\"There are {} samples in the testing dataset\".format(Xtest.shape[0]))\n",
    "print(\"Each sample has {} features\".format(Xtrain.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the p-values of the target with respect to the variables\n",
    "_, p_values = f_regression(X,y)\n",
    "p_values_show = pd.DataFrame({'Variable': X.columns, 'p-value': p_values})\n",
    "p_values_show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var = 'adults_n'\n",
    "# use those sets to performe univariate linear regression\n",
    "X_train_r = Xtrain[pred_var].values.reshape(-1,1) # transform a series into a one-column array\n",
    "X_test_r = Xtest[pred_var].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regressor object\n",
    "linear_multi = LinearRegression()\n",
    "# Train the model using the training set\n",
    "linear_multi.fit(Xtrain, ytrain)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_train_pred_multi = linear_multi.predict(Xtrain)\n",
    "y_test_pred_multi = linear_multi.predict(Xtest)\n",
    "\n",
    "# Show the coefficients of the predicting variables\n",
    "pd.DataFrame({'Variable': X.columns, 'Coefficient': linear_multi.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the statistical significance\n",
    "_, p_values = f_regression(Xtrain,y_train_pred_multi)\n",
    "p_values_show = pd.DataFrame({'Variable': X.columns, 'p-value': p_values})\n",
    "p_values_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the quality measures\n",
    "\n",
    "#perform F-test\n",
    "f_statistic_multi, p_value_multi = f_test(ytrain, y_train_pred_multi\n",
    "                                        , Xtrain.shape[1], Xtrain.shape[0])\n",
    "                                        \n",
    "# The mean squared error\n",
    "rmse_multi = mean_squared_error(ytest, y_test_pred_multi, squared=False)\n",
    "# print(\"The MSE for the multivariate linear regression of '{target}' is: {rmse_dt:8.2f}\")\n",
    "\n",
    "# Coefficient of determination=1 is perfect prediction\n",
    "r2_multi = r2_score(ytest, y_test_pred_multi)\n",
    "# print(\"The 'R square' for the multivariate linear regression of '{target}' is: {r2_dt:8.2f}\")\n",
    "\n",
    "pd.DataFrame({'Univariate Linear - Value' : [rmse_multi\n",
    "                        , r2_multi\n",
    "                        , f_statistic_multi\n",
    "                        , p_value_multi]}\n",
    "            , index = ['rmse'\n",
    "                     , 'r2'\n",
    "                     , 'f-statistic'\n",
    "                     , 'p-value']).style.format(precision=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Multivariate Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Decision Tree regressor object\n",
    "dt = DecisionTreeRegressor(random_state=random_state)\n",
    "# Train the model using the training set\n",
    "dt.fit(Xtrain, ytrain);\n",
    "max_max_depth = dt.tree_.max_depth\n",
    "print(\"The maximum depth of the full Decision Tree Regressor is {}\".format(max_max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the gris search cross validation object \n",
    "# and finding the best depth of the tree\n",
    "param_grid = {'max_depth': list(range(1,max_max_depth))}\n",
    "dt_gscv = GridSearchCV(estimator=DecisionTreeRegressor(random_state=random_state)\n",
    "                    , param_grid=param_grid\n",
    "                    , scoring='neg_mean_squared_error' # select model with minimum mse\n",
    "                    )\n",
    "dt_gscv.fit(Xtrain,ytrain);\n",
    "dt_best = dt_gscv.best_estimator_ # the GridSearchCV returns the best estimator\n",
    "best_max_depth = dt_best.tree_.max_depth\n",
    "print(f\"The optimal maximum depth for the decision tree is {best_max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the test set\n",
    "y_test_pred_dt = dt_best.predict(Xtest)\n",
    "rmse_dt = mean_squared_error(ytest, y_test_pred_dt, squared=False)\n",
    "print(f\"Decision Tree Regression - RMSE = {rmse_dt:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the tree\n",
    "figure(figsize = (20,15))\n",
    "plot_tree(dt_best\n",
    "          , filled = True # fills nodes with colors related to classes\n",
    "                          # darker color means higher purity\n",
    "          , feature_names = X.columns\n",
    "          , fontsize=18\n",
    "        #   , class_names = df[target].unique()\n",
    "         );"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Multivariate Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest regression object\n",
    "rf = RandomForestRegressor(random_state=random_state)\n",
    "# for simplicity, we use as a maximum maximum depth of the tree the value found in\n",
    "# the unconstrained decision tree fitting\n",
    "param_grid_rf = {'max_depth': list(range(1,max_max_depth))\n",
    "}\n",
    "# create the grid search with cross validation\n",
    "rf_gscv = GridSearchCV(rf, param_grid=param_grid_rf\n",
    "                        , scoring='neg_mean_squared_error') # look for minimum mean square error\n",
    "\n",
    "# Train the model using the training set\n",
    "rf_gscv.fit(Xtrain, ytrain)\n",
    "\n",
    "# the grid search returns the best estimator\n",
    "rf = rf_gscv.best_estimator_\n",
    "\n",
    "print(\"The optimal maximum depth for the trees in the random forest is {}\".format(rf.max_depth))\n",
    "\n",
    "y_test_pred_rf = rf.predict(Xtest)\n",
    "rmse_rf = mean_squared_error(ytest, y_test_pred_rf, squared=False)\n",
    "print(\"Random Forest Regression - RMSE = {rmse_rf:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the distribution of the data\n",
    "plt.scatter(X,y)\n",
    "plt.xlabel(\"Temperature\");\n",
    "plt.ylabel(\"Demand\");\n",
    "plt.show()\n",
    "\n",
    "# divide the data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first experiment with a  linear model\n",
    "lmodel = LinearRegression()\n",
    "lmodel.fit(X.temp.values.reshape(-1,1), y)\n",
    "lin = print_eval(Xtest, ytest, lmodel)\n",
    "# visualizing the prediction of the model\n",
    "lpred = lmodel.predict(np.arange(min(X.temp), max(X.temp)).reshape(-1,1))\n",
    "plt.plot(np.arange(min(X.temp), max(X.temp)),lpred, label = \"lin\", color = \"red\")\n",
    "plt.legend()\n",
    "plt.scatter(X,y)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second experiment with a polynomial regressor\n",
    "polFea = PolynomialFeatures(2,include_bias=False)\n",
    "X_poly = polFea.fit_transform(Xtrain.values)#.reshape(-1,1))\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, ytrain)\n",
    "pol = print_eval(polFea.transform(Xtest), ytest, model)\n",
    "\n",
    "# plotting the polynomial regressor\n",
    "pred = model.predict(polFea.transform((np.arange(min(X.temp), max(X.temp))).reshape(-1,1)))\n",
    "plt.plot(np.arange(min(X.temp), max(X.temp)),pred, label = \"poly\",color=\"red\")\n",
    "plt.legend()\n",
    "plt.scatter(X,y)\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third expreriment\n",
    "polFea = PolynomialFeatures(3,include_bias=False)\n",
    "print(\"Polynomial degree = 3\")\n",
    "X_poly = polFea.fit_transform(Xtrain.values)#.reshape(-1,1))\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, ytrain)\n",
    "\n",
    "pol3 = print_eval(polFea.transform(Xtest), ytest, model)\n",
    "\n",
    "pred3 = model.predict(polFea.transform((np.arange(min(X.temp), max(X.temp))).reshape(-1,1)))\n",
    "plt.plot(np.arange(min(X.temp), max(X.temp)),pred3, label = \"poly\",color=\"red\")\n",
    "plt.legend()\n",
    "plt.scatter(X,y)\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the performance of the models\n",
    "performance = {\"linear \": [*lin],\n",
    "                \"polynomial d = 2\": [*pol],\n",
    "                \"polynomial d = 3\": [*pol3] }\n",
    "res = pd.DataFrame(performance, index = ['rmse'\n",
    "                     , 'r2'\n",
    "                     , 'f-statistic'\n",
    "                     , 'p-value'])\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
