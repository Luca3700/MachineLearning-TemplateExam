{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, pair_confusion_matrix, plot_confusion_matrix\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "\n",
    "random_state = 42 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_plots(x, y1, y2, xlabel, y1label, y2label):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax1.set_ylabel(y1label, color=color)\n",
    "    ax1.plot(x, y1, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel(y2label, color=color)  # we already handled the x-label with ax1\n",
    "    ax2.plot(x, y2, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.set_ylim(0,1) # the axis for silhouette is [0,1]\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()\n",
    "\n",
    "#from plot_clusters import plot_clusters\n",
    "def plot_clusters(X, y, dim, points,\n",
    "                  labels_prefix = 'cluster', \n",
    "                  points_name = 'centroids',\n",
    "                  colors = cm.tab10, # a qualitative map \n",
    "                      # https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "#                   colors = ['brown', 'orange', 'olive', \n",
    "#                             'green', 'cyan', 'blue', \n",
    "#                             'purple', 'pink'],\n",
    "#                   points_color = 'red'\n",
    "                  points_color = cm.tab10(10) # by default the last of the map (to be improved)\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Plot a two dimensional projection of an array of labelled points\n",
    "    X:      array with at least two columns\n",
    "    y:      vector of labels, length as number of rows in X\n",
    "    dim:    the two columns to project, inside range of X columns, e.g. (0,1)\n",
    "    points: additional points to plot as 'stars'\n",
    "    labels_prefix: prefix to the labels for the legend ['cluster']\n",
    "    points_name:   legend name for the additional points ['centroids']\n",
    "    colors: a color map\n",
    "    points_color: the color for the points\n",
    "    @author: Claudio Sartori\n",
    "    \"\"\"\n",
    "    # plot the labelled (colored) dataset and the points\n",
    "    labels = np.unique(y)\n",
    "    for i in range(len(labels)):\n",
    "        color = colors(i / len(labels)) # choose a color from the map\n",
    "        plt.scatter(X[y==labels[i],dim[0]], \n",
    "                    X[y==labels[i],dim[1]], \n",
    "                    s=10, \n",
    "                    c = [color], # scatter requires a sequence of colors\n",
    "                    marker='s', \n",
    "                    label=labels_prefix+str(labels[i]))\n",
    "    plt.scatter(points[:,dim[0]], \n",
    "                points[:,dim[1]], \n",
    "                s=50, \n",
    "                marker='*', \n",
    "                c=[points_color], \n",
    "                label=points_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()  \n",
    "\n",
    "\n",
    "def plot_silhouette(silhouette_vals, y, \n",
    " \t\t\t\t\tcolors = cm.tab10,\n",
    " \t\t\t\t\tplot_noise = False\n",
    "\t\t\t\t\t):\n",
    "    \"\"\"\n",
    "    Plotting silhouette scores for the individual samples of a labelled data set.\n",
    "    The scores will be grouped according to labels and sorted in descending order.\n",
    "    The bars are proportional to the score and the color is determined by the label.\n",
    "    \n",
    "    silhouette_vals: the silhouette values of the samples\n",
    "    y:               the labels of the samples\n",
    "    plot_noise:      boolean, assumes the noise to be labeled with a negative integer\n",
    "    @author: Claudio Sartori\n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(y)\n",
    "    if not plot_noise:\n",
    "\t    cluster_labels = cluster_labels[cluster_labels != -1]\n",
    "    n_clusters = len(cluster_labels)\n",
    "    y_ax_lower, y_ax_upper = 0, 0\n",
    "    yticks = []\n",
    "    for i, c in enumerate(cluster_labels): # generate pairs index, cluster_label\n",
    "        c_silhouette_vals = silhouette_vals[y==c] # extracts records with the current cluster label\n",
    "        c_silhouette_vals.sort() # sort the silhouette vals for the current class\n",
    "        y_ax_upper += len(c_silhouette_vals)\n",
    "        color = colors(i / n_clusters)\n",
    "        plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                edgecolor='none', color=color)\n",
    "        yticks.append((y_ax_lower + y_ax_upper) / 2)\n",
    "        c_silhouette_avg = np.mean(c_silhouette_vals)\n",
    "        plt.axvline(c_silhouette_avg\n",
    "         \t\t\t, ymin = y_ax_lower/len(silhouette_vals)\n",
    "         \t\t\t, ymax = y_ax_upper/len(silhouette_vals)\n",
    "        \t\t\t, color=color, linestyle=\"-.\"\n",
    "        \t\t\t) \n",
    "        y_ax_lower += len(c_silhouette_vals)\n",
    "\n",
    "\n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color=\"black\", linestyle=\"--\") \n",
    "    plt.yticks(yticks, cluster_labels)\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.xlabel('Silhouette coefficient - Cluster means: -. Global mean: --')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('./figures/silhouette.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00292/Wholesale%20customers%20data.csv'\n",
    "delimiter = ','\n",
    "df = pd.read_csv(X_url, delimiter=delimiter)\n",
    "print(f\"Shape of the input data {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "X_sqrt = pd.concat([df.iloc[:,:2],df.iloc[:,2:].applymap(sqrt)],axis=1)\n",
    "\n",
    "# remap on the 0:1 range with MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X = pd.DataFrame(mms.fit_transform(X_sqrt), columns = X_sqrt.columns)\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the elbow method to fid the optinmal number of clusters\n",
    "\n",
    "k_range = list(range(2,11)) # set the range of k values to test \n",
    "parameters_km = [{'n_clusters': k_range}]\n",
    "pg = list(ParameterGrid(parameters_km))\n",
    "inertias_km = []\n",
    "silhouette_scores_km = []\n",
    "for i in range(len(pg)):\n",
    "    km = KMeans(**(pg[i]), random_state=random_state)\n",
    "    y_km = km.fit_predict(df)\n",
    "    inertias_km.append(km.inertia_)\n",
    "    silhouette_scores_km.append(silhouette_score(df, y_km))\n",
    "\n",
    "two_plots(x=k_range, y1=inertias_km, y2=silhouette_scores_km\n",
    "          , xlabel='Number of clusters', y1label='Inertias', y2label='Silhouette scores'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster with the optimal number (the one where the silhouette score is maximum)\n",
    "\n",
    "k=3\n",
    "km = KMeans(n_clusters=k, \n",
    "            random_state=random_state)\n",
    "y_km = km.fit_predict(df)\n",
    "print(f\"Number of clusters = {k}\\n\\\n",
    "    Distortion = {inertias_km[k_range.index(k)]:6.2f}\\t- \\\n",
    "        Silhouette score = {silhouette_scores_km[k_range.index(k)]:4.2f}\")\n",
    "\n",
    "clust_sizes_km = np.unique(y_km,return_counts=True)\n",
    "pd.DataFrame(clust_sizes_km[1]).plot.pie(y=0, autopct='%1.1f%%', );\n",
    "plt.show()\n",
    "\n",
    "# The __silhouette score__ ranges from `-1` (worst) to `1` (best); \n",
    "# as a rule of thumb, a value greater than `0.5` should be considered acceptable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering\n",
    "We will try a grid of parameter configurations, with the number of clusters in the range `2:10` and the four linkage methods available in the *sklearn* implementation of *AgglomerativeClustering*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'n_clusters': k_range, \\\n",
    "    'linkage' : ['ward', 'complete', 'average', 'single']}]\n",
    "pg = list(ParameterGrid(parameters))\n",
    "result_ac = []\n",
    "for i in range(len(pg)):\n",
    "    ac = AgglomerativeClustering(**(pg[i]))\n",
    "    y_ac = ac.fit_predict(df)\n",
    "    result_ac.append([pg[i]['linkage'],pg[i]['n_clusters'],silhouette_score(df,y_ac)])\n",
    "\n",
    "# showing the best results\n",
    "df_result_ac = pd.DataFrame(data = result_ac, columns=['linkage','n_clusters','silhouette_score'])\n",
    "df_result_ac.sort_values(by='silhouette_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 3d bar graph\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe = OrdinalEncoder()\n",
    "df_result_ac['linkage_enc'] = oe.fit_transform(df_result_ac['linkage'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "# x, y = np.meshgrid(np.arange(0,len(data[0]),1) + 0.25, \n",
    "#     np.arange(0,len(data[:,0]),1) + + 0.25)\n",
    "\n",
    "x,y = df_result_ac['linkage_enc'].values,df_result_ac['n_clusters'].values\n",
    "bottom = np.zeros(df_result_ac.shape[0])\n",
    "\n",
    "\n",
    "width = .5 * np.ones(df_result_ac.shape[0])#np.ones_like(zpos)\n",
    "depth = .5 * np.ones(df_result_ac.shape[0])\n",
    "\n",
    "ax.bar3d(x,y\n",
    "         ,bottom,width,depth\n",
    "         ,df_result_ac['silhouette_score'].values\n",
    "         )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result obtained with the best result\n",
    "# The first 3 result have a similar silhouette score, so we choose the one \n",
    "# with the lower number of clusters (in the position 1)\n",
    "\n",
    "pos = 1\n",
    "print(df_result_ac.iloc[[pos]])\n",
    "ac = AgglomerativeClustering(**(pg[pos]))\n",
    "y_ac = ac.fit_predict(df)\n",
    "\n",
    "# show the distribution of the clusters\n",
    "clust_sizes_ac = np.unique(y_ac,return_counts=True)\n",
    "pd.DataFrame(clust_sizes_ac[1]).plot.pie(y=0, autopct='%1.1f%%', );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the prediction of the clustering models to the dataframe\n",
    "df['cluster_km']=y_km\n",
    "sns.pairplot(data=df, hue='cluster_km');\n",
    "plt.show()\n",
    "\n",
    "df['cluster_ac']=y_ac\n",
    "sns.pairplot(data=df.drop('cluster_km',axis=1), hue='cluster_ac');\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "The function `pair_confusion_matrix` computes the number of pairs of objects that are in the same clusters or in different clusters in two different clustering schemes. \n",
    "\n",
    "The result is given in a 2x2 matrix, the perfect match is when only the numbers in the main diagonal are non zero.\n",
    "\n",
    "We present here the results normalized to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcm = pair_confusion_matrix(y_km,y_ac)\n",
    "print(pcm / pcm.sum())\n",
    "print(f\"The percentage of match between the two clustering schemes is {((pcm / pcm.sum()).diagonal().sum()*100):6.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this plot to see the most relevant column\n",
    "sns.pairplot(pd.DataFrame(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[:,[0,1]]\n",
    "focus = [0,1]\n",
    "\n",
    "# observe the most interesting columns\n",
    "plt.scatter(X[:,focus[0]], X[:,focus[1]]\n",
    "            , c='white'          # color filling the data markers\n",
    "            , edgecolors='black' # edge color for data markers\n",
    "            , marker='o'         # data marker shape, e.g. triangles (v<>^), square (s), star (*), ...\n",
    "            , s=50)              # data marker size\n",
    "plt.grid()  # plots a grid on the data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN()\n",
    "y_db = db.fit_predict(X)\n",
    "print(f\"The maximum distance between two samples for one to be considered as in the neighborhood of the other is {db.eps}\\n\\\n",
    "    The number of samples in a neighborhood for a point to be considered as a core point is {db.min_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_all = np.unique(y_db)\n",
    "cluster_labels = cluster_labels_all[cluster_labels_all != -1]\n",
    "n_clusters = len(cluster_labels)\n",
    "if cluster_labels_all[0] == -1:\n",
    "    noise = True\n",
    "    print(\"There is noise\")\n",
    "else:\n",
    "    noise = False\n",
    "print(\"There is/are {} cluster(s)\".format(n_clusters))\n",
    "\n",
    "cluster_centers = np.empty((n_clusters,X.shape[1]))\n",
    "for i in cluster_labels:\n",
    "    cluster_centers[i,:] = np.mean(X[y_db==i,:], axis = 0)\n",
    "plot_clusters(X,y_db,dim=(focus[0],focus[1]), points = cluster_centers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best parameters using `ParameterGrid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'eps': list(np.arange(0.01, 1, 0.01)), 'min_samples': list(range(1,10,1))}\n",
    "params = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Arrange DBSCAN results in a dataframe, for easier presentation and filtering\n",
    "dbscan_out = pd.DataFrame(columns =  ['eps','min_samples','n_clusters','silhouette', 'unclust%'])\n",
    "for i in range(len(params)):\n",
    "    db = DBSCAN(**(params[i]))\n",
    "    y_db = db.fit_predict(X)\n",
    "    cluster_labels_all = np.unique(y_db)\n",
    "    cluster_labels = cluster_labels_all[cluster_labels_all != -1]\n",
    "    n_clusters = len(cluster_labels)\n",
    "    if n_clusters > 1:\n",
    "        X_cl = X[y_db!=-1,:]\n",
    "        y_db_cl = y_db[y_db!=-1]\n",
    "        silhouette = silhouette_score(X_cl,y_db_cl)\n",
    "        uncl_p = (1 - y_db_cl.shape[0]/y_db.shape[0]) * 100\n",
    "        dbscan_out.loc[len(dbscan_out)] = [db.eps, db.min_samples, n_clusters, silhouette, uncl_p]\n",
    "\n",
    "\n",
    "sil_thr = 0.7  # visualize results only for combinations with silhouette above the threshold\n",
    "unc_thr = 10 # visualize results only for combinations with unclustered below the threshold\n",
    "n_clu_max_thr = 4\n",
    "dbscan_out[(dbscan_out['silhouette']>=sil_thr)\\\n",
    "         & (dbscan_out['unclust%']<=unc_thr)\\\n",
    "         & (dbscan_out['n_clusters']<=n_clu_max_thr)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe visually the most promising combination of parameters.  \n",
    "- Plot the clusters with the centers  \n",
    "- Plot the silhouette indexs for all the clustered samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = DBSCAN(eps=0.9, min_samples=4)    #  no\n",
    "# db = DBSCAN(eps=0.28, min_samples=9) # no\n",
    "db = DBSCAN(eps=0.99, min_samples=9)\n",
    "# db = DBSCAN(eps=0.05, min_samples=9)\n",
    "# db = DBSCAN(eps=0.16, min_samples=9)\n",
    "y_db = db.fit_predict(X)\n",
    "cluster_labels_all = np.unique(y_db)\n",
    "cluster_labels = cluster_labels_all[cluster_labels_all != -1]\n",
    "n_clusters = len(cluster_labels)\n",
    "\n",
    "cluster_centers = np.empty((n_clusters,X.shape[1]))\n",
    "for i in cluster_labels:\n",
    "    cluster_centers[i,:] = np.mean(X[y_db==i,:], axis = 0)\n",
    "\n",
    "print(\"There are {} clusters\".format(n_clusters))\n",
    "print(\"The cluster labels are {}\".format(cluster_labels))\n",
    "print(f\"Cluster centers: {cluster_centers}\")\n",
    "\n",
    "plot_clusters(X,y_db,dim=(focus[0],focus[1]), points = cluster_centers)\n",
    "\n",
    "silhouette = silhouette_samples(X,y_db)\n",
    "plot_silhouette(silhouette,y_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look to the width of data ranges\n",
    "print(np.max(X, axis=0)-np.min(X,axis=0))\n",
    "\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "Xs = mms.fit_transform(X)\n",
    "Xs.max(axis=0)-Xs.min(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
